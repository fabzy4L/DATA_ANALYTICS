{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec5e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4192882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f22eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store book information\n",
    "videos = []\n",
    "\n",
    "# Loop through pages 1 to 4\n",
    "for i in range(1, 5):\n",
    " \n",
    "#/Users/f4L/Documents/Profile.pdf\n",
    "\n",
    "    # Generate the URL for each page\n",
    "    url = f\"https://www.pornhub.com/\"\n",
    "    #url = f\"https://books.toscrape.com/catalogue/page-{i}.html\"    \n",
    "    #url = f\"https://www.linkedin.com/in/fpalvarez23/\"\n",
    "    \n",
    "        \n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Get the content of the response\n",
    "    response = response.content\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0a24625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the PDF from your local machine\n",
    "pdf_file_path = '/Users/f4L/Documents/Profile.pdf'  # Replace with the path to your PDF file\n",
    "\n",
    "# Extract text from the PDF\n",
    "pdf_text = ''\n",
    "with open(pdf_file_path, 'rb') as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        pdf_text += page.extract_text()\n",
    "\n",
    "# Create a BeautifulSoup object to parse the extracted text\n",
    "soup = BeautifulSoup(pdf_text, 'html.parser')\n",
    "\n",
    "# Now you can work with the parsed text using BeautifulSoup\n",
    "# For example, you can find elements or extract specific data from the text\n",
    "# Example:\n",
    "titles = soup.find_all('h1')  # Find all <h1> elements in the parsed text\n",
    "\n",
    "for title in titles:\n",
    "    print(title.text)  # Print the text content of each <h1> element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e60ecddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfef727",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    # Find the <ol> (ordered list) element containing book information\n",
    "    ul = soup.find('ul')\n",
    "    \n",
    "    # Find all <article> elements with the class 'product_pod'\n",
    "    divisions = ul.find_all('div', class_='phimage')\n",
    "    \n",
    "   # class=\"display-flex flex-row justify-space-between\"\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a8768",
   "metadata": {},
   "source": [
    "# Find the h1 element with the specified class\n",
    "name_element = soup.find('h1', class_='text-heading-xlarge')\n",
    "\n",
    "# Extract the text content from the element\n",
    "name = name_element.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4fd061",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Loop through each book article\n",
    "    for division in divisions:\n",
    "        # Find the <img> element containing the book image\n",
    "        image = division.find('img')\n",
    "        \n",
    "        # Extract the book title from the 'alt' attribute of the image\n",
    "        title = image.attrs['alt']\n",
    "        \n",
    "        # Append book information as a list to the 'books' list\n",
    "        books.append([title])\n",
    "\n",
    "# Create a DataFrame from the list of books with specified column names\n",
    "df = pd.DataFrame(videos, columns=['Title'])\n",
    "\n",
    "# Save the DataFrame to a CSV file named 'books.csv'\n",
    "df.to_csv('videos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b90b513",
   "metadata": {},
   "source": [
    "# Create an empty list to store book information\n",
    "books = []\n",
    "\n",
    "# Loop through pages 1 to 4\n",
    "for i in range(1, 5):\n",
    "    \n",
    "    # Generate the URL for each page\n",
    "    #url = f\"https://books.toscrape.com/catalogue/page-{i}.html\"    \n",
    "    url = f\"https://books.toscrape.com/catalogue/category/books_1/index.html\"\n",
    "    \n",
    "        \n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Get the content of the response\n",
    "    response = response.content\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    \n",
    "    # Find the <ol> (ordered list) element containing book information\n",
    "    ol = soup.find('ol')\n",
    "    \n",
    "    # Find all <article> elements with the class 'product_pod'\n",
    "    articles = ol.find_all('article', class_='product_pod')\n",
    "    \n",
    "    # Loop through each book article\n",
    "    for article in articles:\n",
    "        # Find the <img> element containing the book image\n",
    "        image = article.find('img')\n",
    "        \n",
    "        # Extract the book title from the 'alt' attribute of the image\n",
    "        title = image.attrs['alt']\n",
    "        \n",
    "        # Find the <p> element containing star rating information\n",
    "        starTag = article.find('p')\n",
    "        \n",
    "        # Extract the star rating from the second class in 'class' attribute\n",
    "        star = starTag['class'][1]\n",
    "        \n",
    "        # Find the <p> element with class 'price_color' and extract the price\n",
    "        price = article.find('p', class_='price_color').text\n",
    "        \n",
    "        # Convert the price string to a float, removing the currency symbol\n",
    "        price = float(price[1:])\n",
    "        \n",
    "        # Append book information as a list to the 'books' list\n",
    "        books.append([title, star, price])\n",
    "\n",
    "# Create a DataFrame from the list of books with specified column names\n",
    "df = pd.DataFrame(books, columns=['Title', 'Star Rating', 'Price'])\n",
    "\n",
    "# Save the DataFrame to a CSV file named 'books.csv'\n",
    "df.to_csv('books.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
